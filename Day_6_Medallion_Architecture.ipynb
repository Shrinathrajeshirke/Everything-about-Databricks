{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a3363b3-337c-435e-8556-7d7563539d1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Bronze (raw) → Silver (cleaned) → Gold (aggregated)\n",
    "\n",
    "- This is the **Medallion Architecture**, the industry standard for organizing data in a Lakehouse. \n",
    "- Instead of having one giant, messy pile of data, you move it through three stages of \"refining\".\n",
    "- The Medallion Architecture is a data design pattern used to organize data as it flows through a system. \n",
    "- Think of it like a water filtration system: as water moves through different filters, it gets cleaner and safer to drink.\n",
    "- In a data lakehouse, we move data through three distinct \"buckets\" to go from messy, raw files to clean, useful reports.\n",
    "\n",
    "**1. Bronze (The Raw Layer)**\n",
    "- This is the entry point for all your data. \n",
    "- You don't change anything here. \n",
    "- If the source data has errors, typos, or duplicates, you keep them exactly as they are. \n",
    "- This acts as your \"Source of Truth\"—if anything goes wrong later, you can always come back here to restart the process.\n",
    "\n",
    "**2. Silver (The Validated Layer)**\n",
    "- In this stage, you take your Bronze data and \"clean\" it. \n",
    "- You act like a filter to make the data high-quality. You perform tasks like:\n",
    "- Removing duplicate records.\n",
    "- Fixing \"null\" or missing values.\n",
    "- Ensuring dates and numbers are in the correct format.\n",
    "- Merging different tables together to provide a more complete picture.\n",
    "\n",
    "**3. Gold (The Enriched Layer)**\n",
    "- This is the final stage where the data is ready for the \"business\" to see. \n",
    "- Instead of millions of individual rows, Gold tables usually contain summaries. \n",
    "- The data here is organized to answer specific questions, like \"What are the total sales per month?\" or \"Which region has the most active users?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e60715b-0082-47b5-b6ea-504679018a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Best practices for each layer\n",
    "\n",
    "**1. Bronze Layer (Raw)**\n",
    "- **The Golden Rule: Touch nothing.**\n",
    "- **Keep it Immutable:** Never edit the data in this layer. It should be an exact \"snapshot\" of what came from the source.\n",
    "- **Append Only:** Instead of updating rows, just keep adding new data to the end of the table.\n",
    "- **Use Folders/Schema:** Organize your raw data by the date it arrived (e.g., year=2026/month=01/day=14).\n",
    "- **Retain History:** Keep the raw data for as long as your budget allows. It’s your \"safety net\" if you need to rebuild everything from scratch.\n",
    "\n",
    "**2. Silver Layer (Cleaned)**\n",
    "- **The Golden Rule: Make it \"Query-Ready.\"**\n",
    "- **Enforce Schema:** Ensure that \"Price\" is always a number and \"Date\" is always a date. No more \"garbage\" data allowed.\n",
    "- **Handle Duplicates:** This is where you use the MERGE command to ensure every record is unique.\n",
    "- **Standardize:** If one source uses \"M/F\" for gender and another uses \"Male/Female,\" pick one and stick to it here.\n",
    "- **Data Masking:** If there is sensitive info (like phone numbers or emails), hide or encrypt them in this layer so only authorized people can see them.\n",
    "\n",
    "**3. Gold Layer (Business)**\n",
    "- **The Golden Rule: Make it fast and simple.**\n",
    "- **Pre-calculate:** Instead of making the user calculate \"Total Profit\" every time, calculate it once and store it here.\n",
    "- **Use Clear Names:** Use column names that a non-technical person understands (e.g., total_monthly_revenue instead of sum_rev_01).\n",
    "- **Apply Optimization:** This is the best place to use ZORDER on columns that people use in filters (like Region or Category).\n",
    "- **Keep it Lean:** Only include the columns needed for reports. Don't carry over technical IDs or \"junk\" columns from Silver.\n",
    "\n",
    "**Summary of Best Practices**\n",
    "| Feature | Bronze | Silver | Gold |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| Data Quality | Raw/Unverified | Cleaned/Verified | Highly Processed\n",
    "| Format | Delta (or original) | Delta | Delta\n",
    "| Storage Strategy | Append-only | Upsert (Merge) | Overwrite or Append\n",
    "| Primary User | Data Engineers | Data Scientists | Business Analysts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d487b01-d5c9-4ef0-a613-79f3b58863a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Incremental processing patterns\n",
    "\n",
    "- Incremental processing means only moving the new or changed data from one layer to the next. \n",
    "- Instead of reprocessing millions of rows every day, you only touch the \"delta\" (the new stuff).\n",
    "\n",
    "**1. The Append Pattern (Easiest)**\n",
    "- This is used when your data only flows in one direction and never changes.\n",
    "- **How it works:** You check the last time your pipeline ran, look for files created after that time, and add them to the next layer.\n",
    "- **Best for:** Logs, sensor readings, or clickstream data where old records are never updated.\n",
    "\n",
    "**2. The Upsert Pattern (Merge)**\n",
    "- This is used when your source data can change (e.g., a customer changes their phone number).\n",
    "- **How it works:** You use the MERGE command. It looks at the new batch of data:\n",
    "- If the ID exists in Silver, it Updates the row.\n",
    "- If the ID is brand new, it Inserts it.\n",
    "- **Best for:** Customer profiles, inventory levels, or student grades.\n",
    "- **Benefit:** It keeps your Silver/Gold layers perfectly in sync with the source without creating duplicates.\n",
    "\n",
    "**3. Change Data Capture (CDC)**\n",
    "- This is the most \"pro\" way to do incremental processing. \n",
    "- Some databases provide a special log that tells you exactly what changed: \"Row 5 was deleted,\" \"Row 10 was updated,\" \"Row 12 was added.\"\n",
    "- **How it works:** Delta Lake has a feature called Change Data Feed (CDF). It records the \"before\" and \"after\" for every single change.\n",
    "- **Best for:** Complex systems where you need to know not just the current value, but how it changed over time.\n",
    "\n",
    "**4. Structured Streaming (Auto-Pilot)**\n",
    "- In Databricks, the most common way to handle all the patterns above is using Structured Streaming.\n",
    "- The \"Trigger Once\" Trick: Even if you only want to run your code once a day (Batch), you can use the streaming API. It automatically keeps track of which files it has already processed using a \"checkpoint\" folder.\n",
    "- How it looks in code:\n",
    "```\n",
    "(spark.readStream\n",
    "  .format(\"cloudFiles\") # Auto-loader\n",
    "  .option(\"cloudFiles.format\", \"csv\")\n",
    "  .load(bronze_path)\n",
    "  .writeStream\n",
    "  .trigger(availableNow=True) # Process all new data then stop\n",
    "  .checkpointLocation(checkpoint_path)\n",
    "  .toTable(\"silver_table\"))\n",
    "```\n",
    "\n",
    "**Why use Incremental Processing?**\n",
    "- Cost: Processing 1,000 new rows is much cheaper than processing 10 billion old ones.\n",
    "- Speed: Your \"Gold\" reports update in minutes instead of hours.\n",
    "- Scalability: As your business grows, your pipeline stays fast because the \"daily work\" stays roughly the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc98ea34-786e-438d-8854-5484ab613015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Task 1: Design 3-Layer Architecture\n",
    "\n",
    "1. Bronze: ecommerce_bronze (Raw strings/as-is)\n",
    "2. Silver: ecommerce_silver (Cleaned, typed, and deduplicated)\n",
    "3. Gold: ecommerce_gold_brand_metrics (Aggregated for business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a69096a0-28ed-4f68-89c2-0e6d9a354856",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Task 2: Build Bronze (Raw Ingestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9f1bd5e-8169-47e6-928c-a0efd31a8f0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to your downloaded CSV\n",
    "file_path = \"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv\"\n",
    "\n",
    "# Read the file with correct options\n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", \"true\")        # Uses the first row as column names\n",
    "      .option(\"inferSchema\", \"true\")   # Automatically detects data types (e.g., price as double)\n",
    "      .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "281aa470-8ed1-49e4-8759-a02a7b18ea2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify the result\n",
    "df.printSchema()\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12b9f097-15f5-4ba1-977a-39925b102108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### save to bronze\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(\"ecommerce_bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "531d6b3a-183d-40c5-ab55-c8c035ed5142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Task 3: Build Silver (Cleaning & Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e14aa3ad-dc50-4f44-bfba-5cb28852679e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split, coalesce, lit, to_timestamp\n",
    "\n",
    "## Read from bronze\n",
    "bronze_df = spark.table(\"ecommerce_bronze\")\n",
    "\n",
    "## convert string to timestamp\n",
    "step1_df = bronze_df.withColumn(\"event_time\", to_timestamp(col(\"event_time\"), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41b14bad-f367-4869-b375-32117d5f34d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Handle null values\n",
    "step2_df = step1_df.withColumn(\"brand\", coalesce(col(\"brand\"), lit(\"unknown\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa54a80-4868-4213-a7a2-c3a53276033f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import element_at \n",
    "\n",
    "## split the category code\n",
    "step3_df = step2_df.withColumn(\"category_array\", split(col(\"category_code\"), r\"\\.\")).withColumn(\"main_category\", element_at(col(\"category_array\"), 1)).withColumn(\"sub_category\", element_at(col(\"category_array\"), 2)).drop(\"category_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed3ba69f-b57a-4b1a-a54f-7c61b930866c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the silver dataframe\n",
    "silver_df = step3_df.dropDuplicates([\"event_time\", \"user_id\", \"product_id\"])\n",
    "\n",
    "# Save to Silver Table\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ecommerce_silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88a80b8a-0efa-438a-b7db-0bd11b3f3789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Build Gold (Business Aggregates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb2ef4f5-4aab-442d-b3b7-db557471340c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, count, round\n",
    "\n",
    "## filter for purchases and aggregate\n",
    "gold_df = silver_df.filter(col(\"event_type\") == \"purchase\").groupby(\"brand\",\"main_category\").agg(\n",
    "    count(\"*\").alias(\"total_transactions\"),\n",
    "    round(sum(\"price\"),2).alias(\"total_revenue\")\n",
    ")\n",
    "\n",
    "## save the table\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"ecommerce_gold_brand_metrics\")\n",
    "\n",
    "## display results\n",
    "display(gold_df.orderBy(col(\"total_revenue\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f20ac20-343d-4edb-82ea-f0a8c9e7efb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT count(*) FROM ecommerce_silver WHERE event_type = 'purchase';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6dc36b5-b154-49b7-bd68-4dbfa419ad36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT count(*) \n",
    "FROM ecommerce_silver \n",
    "WHERE event_type LIKE '%purchase%';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "333cc014-e8f1-4ae9-b1f6-3de211943202",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE TABLE ecommerce_silver;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8611f317-4ab2-4839-8b3b-4e809e27fa27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day_6_Medallion_Architecture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
