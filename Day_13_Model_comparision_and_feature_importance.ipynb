{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d85c24d0-13e7-477d-9d2c-938b415bf282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Training Multiple Models \n",
    "- In ML, there is no \"best\" model for every dataset. Today, you will run an \"audition\" where you train different types of algorithms to see which one understands your e-commerce data better.\n",
    "- Linear Regression: Good for simple relationships (e.g., \"The more clicks, the more spend\").\n",
    "- Decision Trees: Good for capturing \"If/Then\" logic (e.g., \"If they are on a mobile device AND it's the weekend, they buy more\").\n",
    "- Random Forest / XGBoost: \"Ensemble\" models that combine many small trees to handle the complexity of 42M rows.\n",
    "\n",
    "### 2. Hyperparameter Tuning (The Fine-Tuning)\n",
    "- A model is like a radio; you have to turn the knobs (Hyperparameters) to get a clear signal.\n",
    "- What are they? These are settings you choose before training starts (e.g., max_depth of a tree or learning_rate).\n",
    "- The Pro Way: Instead of guessing, we use Grid Search or Hyperopt in Databricks. This automatically tries 20 different \"knob settings\" and tells you which one worked best.\n",
    "\n",
    "### 3. Feature Importance (The \"Why\")\n",
    "- Once your model is accurate, you need to explain why it's making those predictions. Feature Importance ranks your input data from most to least influential.\n",
    "- Example: You might find that avg_viewed_price is a huge predictor of spend, while interaction_count doesn't matter as much.\n",
    "\n",
    "### 4. Spark ML Pipelines (The Assembly Line)\n",
    "- This is the most \"Engineering\" part of the day. A Pipeline bundles your data cleaning and your model into one single object.\n",
    "- Transformers: Stages that change the data (e.g., turning \"Electronics\" into the number 1).\n",
    "- Estimators: The actual ML algorithm (e.g., Random Forest).\n",
    "- Why use it? When you get a new row of raw data tomorrow, you don't have to manually clean it again. You just pass it to the Pipeline, and it handles everything from cleaning to prediction in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "632210a1-5182-4ac4-bf7c-a631ed2042cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1 & 3: Build the Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6549e41-0144-4e36-99c2-f3d63049a3ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# 1. Prepare Data\n",
    "train_df, test_df = spark.table(\"ecommerce_prod.gold.user_ml_features\").randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Define Pipeline Stages\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['interaction_count', 'weekend_ratio', 'avg_viewed_price', 'category_diversity'], \n",
    "    outputCol=\"raw_features\"\n",
    ")\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# 3. List of Models to \"Audition\"\n",
    "models = [\n",
    "    LinearRegression(labelCol=\"total_spend\", featuresCol=\"features\"),\n",
    "    RandomForestRegressor(labelCol=\"total_spend\", featuresCol=\"features\", numTrees=50),\n",
    "    GBTRegressor(labelCol=\"total_spend\", featuresCol=\"features\", maxIter=20)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf28ea99-5947-42b9-9e1d-09e6a0b07cc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2: Train and Compare in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb707166-31ae-421c-8652-5980230ced01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS ecommerce_prod.ml_staging;\n",
    "CREATE VOLUME IF NOT EXISTS ecommerce_prod.ml_staging.model_tmp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c71b942-6bfe-4613-b682-6b01f752db7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# 1. SETUP: Fix the \"UC Volume Path\" error\n",
    "os.environ['MLFLOW_DFS_TMP'] = \"/Volumes/ecommerce_prod/ml_staging/model_tmp\"\n",
    "user_email = \"shrinathrajeshirke@gmail.com\" # Updated from your error log\n",
    "experiment_path = f\"/Users/{user_email}/day13_comparison\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# 2. DATA PREP: Load features from Day 12\n",
    "data = spark.table(\"ecommerce_prod.gold.user_ml_features\")\n",
    "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 3. PIPELINE COMPONENTS: Build the assembly line\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['interaction_count', 'weekend_ratio', 'avg_viewed_price', 'category_diversity'], \n",
    "    outputCol=\"raw_features\"\n",
    ")\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# 4. MODELS: Define the three candidates\n",
    "models = [\n",
    "    LinearRegression(labelCol=\"total_spend\", featuresCol=\"features\"),\n",
    "    RandomForestRegressor(labelCol=\"total_spend\", featuresCol=\"features\", numTrees=50),\n",
    "    GBTRegressor(labelCol=\"total_spend\", featuresCol=\"features\", maxIter=20)\n",
    "]\n",
    "\n",
    "# 5. EXECUTION: Loop, Train, and Log\n",
    "print(\"Starting Model Audition...\")\n",
    "with mlflow.start_run(run_name=\"Day13_Model_Comparison\") as parent_run:\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        with mlflow.start_run(run_name=model_name, nested=True):\n",
    "            # Construct Pipeline\n",
    "            pipeline = Pipeline(stages=[assembler, scaler, model])\n",
    "            \n",
    "            # Train model\n",
    "            pipeline_model = pipeline.fit(train_df)\n",
    "            \n",
    "            # Make Predictions\n",
    "            predictions = pipeline_model.transform(test_df)\n",
    "            \n",
    "            # Evaluate Performance\n",
    "            evaluator = RegressionEvaluator(labelCol=\"total_spend\", metricName=\"rmse\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            \n",
    "            # Log results\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.spark.log_model(\n",
    "                pipeline_model, \n",
    "                artifact_path=f\"{model_name}_pipeline\",\n",
    "                dfs_tmpdir=os.environ['MLFLOW_DFS_TMP']\n",
    "            )\n",
    "            \n",
    "            print(f\"{model_name} completed. RMSE: {rmse}\")\n",
    "\n",
    "# 6. CHAMPION SELECTION: Pick the best model automatically\n",
    "client = MlflowClient()\n",
    "experiment_id = client.get_experiment_by_name(experiment_path).experiment_id\n",
    "\n",
    "# Find the run with the lowest RMSE\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "best_run = runs[0]\n",
    "best_rmse = best_run.data.metrics['rmse']\n",
    "best_model_run_name = best_run.data.tags['mlflow.runName']\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Best Model: {best_model_run_name}\")\n",
    "print(f\"BEST RMSE: {best_rmse}\")\n",
    "\n",
    "# 7. REGISTER: Save the winner to the Model Registry\n",
    "model_uri = f\"runs:/{best_run.info.run_id}/{best_model_run_name}_pipeline\"\n",
    "mlflow.register_model(model_uri, \"ecommerce_champion_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55a73629-fe5f-45bb-bdb5-763c9b423887",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Programmatically Select the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0252812-89cd-40bc-9fa7-20a7fd746b75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"/Users/shrinathrajeshirke@gmail.com/day13_comparison\")\n",
    "\n",
    "# Search for the best run based on lowest RMSE\n",
    "best_run = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=\"\",\n",
    "    run_view_type=1,\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")[0]\n",
    "\n",
    "best_model_name = best_run.data.tags['mlflow.runName']\n",
    "print(f\"The best model is: {best_model_name} with RMSE: {best_run.data.metrics['rmse']}\")\n",
    "\n",
    "# Register the winner\n",
    "model_uri = f\"runs:/{best_run.info.run_id}/{best_model_name}_pipeline\"\n",
    "mlflow.register_model(model_uri, \"ecommerce_best_predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79cff092-a110-4c9c-8ace-c627f6aa9db2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5529848463061553,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day_13_Model_comparision_and_feature_importance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
