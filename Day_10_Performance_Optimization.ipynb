{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3db7b6ea-1f8c-46c6-ad95-8289fb26ffe2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Query execution plans\n",
    "\n",
    "**How to View the Plan**\n",
    "- In the Databricks SQL Editor, after you run a query, click the \"Query Profile\" tab at the bottom. This opens a graphical representation of the execution plan.\n",
    "\n",
    "**1. The \"Life of a Query\" (Plan Stages)**\n",
    "- When you hit \"Run,\" the SQL Warehouse goes through three main steps:\n",
    "- **Parsing/Analysis:** Checks if your table actually exists and if you have permissions.\n",
    "- **Optimization (The CBO):** The Cost-Based Optimizer looks at table statistics (size, file count) and decides the best way to join tables.\n",
    "- **Physical Plan:** The actual Spark/Photon code that runs on the CPUs.\n",
    "\n",
    "**2. What to Look for in the Query Profile**\n",
    "- When analyzing queries, look for these specific \"Operations\":\n",
    "- **FileScan (Delta):** This is where it reads data from S3/ADLS. Look at \"Data Read\" vs. \"Data Skipped.\" If your query skips 40M rows and only reads 2M, your partitioning is working perfectly.\n",
    "- **PhotonGate:** If you see this, it means the Photon Engine has taken over. This is goodâ€”it means your query is running in highly optimized C++.\n",
    "- **Shuffle (Exchange):** This is the \"expensive\" part where data moves between nodes. If you see massive shuffles, your JOIN or GROUP BY might be inefficient.\n",
    "- **Broadcast Hash Join:** This is the \"Gold Standard\" for performance. It means one table was small enough to be sent to all workers, avoiding a slow shuffle.\n",
    "\n",
    "**3. Optimization Techniques**\n",
    "- If the execution plan shows your query is slow, here are three ways to fix it without changing the code:\n",
    "- **ANALYZE TABLE:** Run ANALYZE TABLE table COMPUTE STATISTICS;. This tells the optimizer exactly how big the table is so it can pick the best plan.\n",
    "- **Z-ORDERING:** If you often filter by brand, run OPTIMIZE table ZORDER BY (column);. This physically rearranges the rows so the \"FileScan\" can skip irrelevant data.\n",
    "- **Data Type Alignment:** Ensure you aren't joining a STRING ID to an INT ID. This forces a \"Cast,\" which can break \"Predicate Pushdown\" (the ability to skip data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b35324a-6910-40c3-b1b6-fe514e162844",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Partitioning strategies\n",
    "\n",
    "**1. The Core Concept: \"Data Skipping\"**\n",
    "- Partitioning physically organizes your data into folders based on a specific column. \n",
    "- When you run a query with a WHERE clause on that column, Databricks \"skips\" every folder that doesn't match, meaning it never even reads those files.\n",
    "\n",
    "**2. Choosing the Right Column**\n",
    "- For e-commerce project, you have three main strategies:\n",
    "**A. Partitioning by Date (event_date)**\n",
    "- Why: Most e-commerce queries ask for \"Last 7 days\" or \"This month.\"\n",
    "- Performance: If you query 1 day of data, the Warehouse only reads ~1/30th of your monthly data.\n",
    "- Implementation:\n",
    "```\n",
    "Python\n",
    "df.write.partitionBy(\"event_date\").saveAsTable(\"...\")\n",
    "```\n",
    "**B. The \"High Cardinality\" Trap**\n",
    "- What to Avoid: Never partition by a column with too many unique values (like user_id or product_id).\n",
    "- The Result: This creates thousands of tiny files (\"The Small File Problem\"), which actually makes the Starter Warehouse slower because of the overhead of opening so many files.\n",
    "**C. Z-Ordering (The Modern Alternative)**\n",
    "- If you need to filter by brand or category frequently, don't partition by them. Instead, use Z-Ordering. It's like a multidimensional index that co-locates related data within the existing files.\n",
    "- Implementation:\n",
    "```\n",
    "SQL\n",
    "OPTIMIZE ecommerce_prod.silver.cleaned_events \n",
    "ZORDER BY (brand, main_category);\n",
    "```\n",
    "\n",
    "**3. Updated Strategy: Liquid Clustering**\n",
    "- As of 2024-2025, Databricks has introduced Liquid Clustering, which replaces traditional partitioning. It is much smarter for Serverless environments because it re-balances itself as your data grows.\n",
    "- If you were to rewrite your Silver table today, you would use this:\n",
    "```\n",
    "SQL\n",
    "CREATE TABLE ecommerce_prod.silver.cleaned_events\n",
    "CLUSTER BY (event_date, brand)\n",
    "AS SELECT * FROM bronze_data;\n",
    "```\n",
    "- Benefit: You don't have to worry about \"over-partitioning.\" The Starter Warehouse handles the file layout automatically.\n",
    "\n",
    "**4. How to check if your partitioning is working**\n",
    "- After running a query in your SQL Warehouse, check the Query Profile:\n",
    "- Look for the FileScan node.\n",
    "- Check the metric: \"files skipped\" vs. \"files read.\"\n",
    "- If \"files skipped\" is a large number, your partitioning strategy is a success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27d6cf23-2b76-49f7-9a68-2c22dd56d75f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### OPTIMIZE & ZORDER\n",
    "\n",
    "- While Partitioning creates physical folders, OPTIMIZE and Z-ORDER work inside those folders to make data access even faster. \n",
    "- This is especially critical for a Serverless Starter Warehouse because it reduces the amount of data the CPU has to process.\n",
    "\n",
    "**1. OPTIMIZE:** The \"Data Cleaner\"\n",
    "- Over time, as you add data to a table, Delta Lake creates many small files. \n",
    "- Reading 1,000 tiny files is much slower than reading one large 1GB file.\n",
    "- **What it does:** It performs file compaction. It takes all those small, fragmented files and merges them into larger, more efficient files (usually ~1GB).\n",
    "- **When to use it:** Run it after a large data load or if your dashboard queries start slowing down.\n",
    "```\n",
    "SQL\n",
    "OPTIMIZE global_flights;\n",
    "```\n",
    "\n",
    "**2. Z-ORDER: The \"Internal Organizer\"**\n",
    "- Z-Ordering is a technique used to co-locate related information in the same set of files. \n",
    "- Think of it like organizing a bookshelf not just by the author's name (Partitioning), but also by the color of the book spine within that section.\n",
    "- **What it does:** It maps multiple columns into a \"space-filling curve.\" This ensures that data with similar values for the Z-Ordered columns are physically stored together.\n",
    "- **The Benefit:** When you filter by a Z-Ordered column, the engine can skip entire files within a partition that don't contain your data.\n",
    "\n",
    "**3. Difference Between Partitioning & Z-Ordering**\n",
    "- It is common to use both together, but they serve different purposes:\n",
    "\n",
    "| Feature | Partitioning | Z-Ordering |\n",
    "| ----- | ----- | ----- |\n",
    "| Physical Structure | Creates separate folders. | Reorganizes data within files.\n",
    "| Best For | Low-cardinality columns (e.g., Year, Country). | High-cardinality columns (e.g., City, Brand).|\n",
    "| Query Benefit | Skips entire folders (Partition Pruning). | Skips files within folders (Data Skipping).\n",
    "| Maintenance | Set once during table creation. | Should be run periodically as data grows.\n",
    "\n",
    "**4. Practical Example (Aviation Table)**\n",
    "- Imagine you have a table partitioned by Year, but your users always filter by Departure_City.\n",
    "- The Query:\n",
    "```\n",
    "SQL\n",
    "SELECT * FROM global_flights \n",
    "WHERE Year = 2024 \n",
    "AND Departure_City = 'London';\n",
    "```\n",
    "- The Optimization Strategy:\n",
    "- Partition by Year: The engine goes straight to the 2024 folder.\n",
    "- Z-Order by Departure_City: Inside the 2024 folder, the engine only opens the 2-3 files that contain 'London' data, skipping the hundreds of other files containing 'Paris' or 'New York'.\n",
    "- The Command:\n",
    "```\n",
    "SQL \n",
    "OPTIMIZE global_flights \n",
    "ZORDER BY (Departure_City);\n",
    "```\n",
    "\n",
    "**5. Modern Alternative: Liquid Clustering**\n",
    "If you are using the latest version of Databricks (which the Serverless Warehouse supports), you can replace both Partitioning and Z-Ordering with Liquid Clustering. It handles all of this automatically without you needing to run OPTIMIZE manually.\n",
    "```\n",
    "SQL\n",
    "CREATE TABLE global_flights\n",
    "CLUSTER BY (Year, Departure_City);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8030eacb-1308-4234-9451-7940c5fc2990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Caching techniques\n",
    "\n",
    "- In a Serverless Starter Warehouse, caching is your best defense against performance bottlenecks. \n",
    "- Because you have a fixed amount of compute, caching ensures that the warehouse doesn't have to re-calculate the same data every time a user refreshes your dashboard.\n",
    "- Databricks uses a three-layered caching strategy to make queries near-instant.\n",
    "\n",
    "**1. Delta Cache (Local SSD Cache)**\n",
    "- This is the most important cache for performance. When you query data from cloud storage (S3/ADLS), the Warehouse stores a copy of that data on the local SSDs of the compute nodes.\n",
    "- **How it works:** The data is stored in an uncompressed, high-speed format.\n",
    "- **The Benefit:** If you run a query for \"Top Products\" and then run it again 5 minutes later, the Warehouse pulls the data from the SSD (microseconds) instead of the cloud storage (milliseconds).\n",
    "- **Maintenance:** On Serverless Warehouses, this is managed automatically. If a node is shut down, the cache is cleared.\n",
    "\n",
    "**2. Query Result Cache**\n",
    "- This cache sits at the \"Top\" level. It doesn't store the data rows; it stores the final answer to your SQL query.\n",
    "- **How it works:** If you run SELECT sum(revenue) FROM sales, and the underlying table hasn't changed, Databricks simply hands you the result from the previous run.\n",
    "- **The Benefit:** It bypasses the entire execution engine (no FileScan, no Shuffle). Results appear in milliseconds.\n",
    "- **Visibility:** You can see this in the Query Profile. It will explicitly state: \"Result served from cache.\"\n",
    "\n",
    "**3. Spark Cache (Memory Cache)**\n",
    "- This is a manual cache often used in Notebooks (PySpark), though less common in SQL Warehouses.\n",
    "- **How it works:** You explicitly tell Spark to keep a specific DataFrame in the RAM (Memory).\n",
    "- **The Command:** df.cache() or df.persist().\n",
    "- **Difference:** Unlike the Delta Cache (which is SSD-based), this is RAM-based. It is faster but much more expensive in terms of resources.\n",
    "\n",
    "- Comparison of Caching Layers\n",
    "\n",
    "| Cache Type | Stored In | Content | Best For | \n",
    "| ----- | ----- | ----- | ----- |\n",
    "| Result Cache | Warehouse Manager | Final Query Output |Repeated Dashboard refreshes.\n",
    "| Delta Cache | Local SSD | Raw Data Blocks | Speeding up different queries on the same table.\n",
    "| Spark Cache | Worker RAM | Processed DataFrames | Iterative Machine Learning or complex joins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb8e8ffd-bb8a-4db2-b5d2-c9b1eefeeeaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1: Analyze Query Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6098fad-9f95-4d45-bf32-f67da6720337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Baseline Query: Checking revenue by brand\n",
    "-- Look at the 'Query Profile' to see if it's reading all 42M rows (FileScan)\n",
    "SELECT \n",
    "  brand, \n",
    "  SUM(price) as total_revenue\n",
    "FROM ecommerce_prod.silver.cleaned_events\n",
    "WHERE event_type = 'purchase'\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b655ff33-e293-437a-9912-2586298a32fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2: Partition Large Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8206e79d-6bc7-4f84-9fb7-97bd82ce3851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE ecommerce_prod.silver.cleaned_events\n",
    "PARTITIONED BY (event_date)\n",
    "AS \n",
    "SELECT \n",
    "  *, \n",
    "  -- Cast to timestamp first, then extract the date to ensure no NULLs\n",
    "  to_date(CAST(event_time AS TIMESTAMP)) AS event_date \n",
    "FROM ecommerce_prod.bronze.raw_events\n",
    "-- Ensure we only bring over rows where the date conversion actually worked\n",
    "WHERE event_time IS NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5639f0c-4b30-4006-8e4d-8818e85da4e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  event_time, \n",
    "  typeof(event_time) as data_type,\n",
    "  brand\n",
    "FROM ecommerce_prod.bronze.raw_events \n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fac087b8-494d-4bdd-a478-ed8973d921d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3: Apply ZORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "defe9d61-06e9-4f7c-950f-3e2e3345dea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE ecommerce_prod.silver.cleaned_events\n",
    "PARTITIONED BY (event_date)\n",
    "AS \n",
    "SELECT \n",
    "  *, \n",
    "  to_date(CAST(event_time AS TIMESTAMP)) AS event_date,\n",
    "  -- Extract the first part of category_code (e.g., 'electronics' from 'electronics.video.tv')\n",
    "  split(category_code, '\\\\.')[0] AS main_category \n",
    "FROM ecommerce_prod.bronze.raw_events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24fe2098-0cbe-404b-ac2e-0149c29070a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT count(*) FROM ecommerce_prod.silver.cleaned_events;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2059b872-d5c3-40da-94ae-4527c08f9a67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 4: Benchmark Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560d9135-48f0-49ef-b380-cba375c75aad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Task 4: Optimized Benchmark\n",
    "SELECT \n",
    "  main_category,\n",
    "  SUM(price) as category_revenue\n",
    "FROM ecommerce_prod.silver.cleaned_events\n",
    "WHERE event_date = '2019-11-01'  -- Use a date found in Step 1\n",
    "  AND brand = 'samsung'          -- Use a brand found in Step 1 (match the casing!)\n",
    "GROUP BY 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14e5b29b-5938-4dd0-b2f3-ad86a91b937c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4617078154624747,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day_10_Performance_Optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
